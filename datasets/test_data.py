import pandas as pd
import json
from pathlib import Path
import os
import pyarrow.parquet as pq
import gc

# =====================================================
# 0. æŒ‡å®šè¦è½¬æ¢çš„ parquet æ–‡ä»¶åˆ—è¡¨
# =====================================================
parquet_files = [
    "/root/autodl-tmp/coda-lm-llava-format/Chinese/Test-00000-of-00004.parquet",
    "/root/autodl-tmp/coda-lm-llava-format/Chinese/Test-00001-of-00004.parquet",
 #   "/root/autodl-tmp/coda-lm-llava-format/Chinese/Test-00002-of-00004.parquet",
    "/root/autodl-tmp/coda-lm-llava-format/Chinese/Test-00003-of-00004.parquet"
]

# =====================================================
# 1. è¾“å‡ºç›®å½•
# =====================================================
base_dir = Path("/root/autodl-tmp/coda-lm-llava-format")
image_output_dir = base_dir / "converted_images_test"
os.makedirs(image_output_dir, exist_ok=True)

output_json_path = base_dir / "qwen_test.json"

print(f"å›¾ç‰‡ä¿å­˜ç›®å½•: {image_output_dir}")
print(f"JSON è¾“å‡ºæ–‡ä»¶: {output_json_path}")

# =====================================================
# 2. æµå¼å†™ JSON æ–‡ä»¶
# =====================================================
with open(output_json_path, "w", encoding="utf-8") as f_json:
    f_json.write('{"type": "vision_language_conversation", "instances": [\n')
    
    first_instance = True
    global_idx = 0
    
    # =====================================================
    # 3. é€ä¸ª parquet æ–‡ä»¶å¤„ç†
    # =====================================================
    for parquet_path in parquet_files:
        parquet_path = Path(parquet_path)
        parquet_name = parquet_path.stem
        print(f"\nå¼€å§‹å¤„ç†æ–‡ä»¶: {parquet_path}")
        
        # --- ä¿®æ”¹ç‚¹ï¼šä½¿ç”¨ PyArrow åˆ›å»ºæ–‡ä»¶å¯¹è±¡ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§åŠ è½½ ---
        parquet_file = pq.ParquetFile(parquet_path)
        
        # --- ä¿®æ”¹ç‚¹ï¼šæŒ‰ Batchï¼ˆæ‰¹æ¬¡ï¼‰è¿­ä»£è¯»å–ï¼Œbatch_size=64 é˜²æ­¢å†…å­˜çˆ†ç‚¸ ---
        # è¿™é‡Œçš„ batch_size å¯ä»¥æ ¹æ®æ˜¾å­˜/å†…å­˜è°ƒæ•´ï¼Œå›¾ç‰‡å¤§å°±è°ƒå°ä¸€ç‚¹
        for batch_idx, batch in enumerate(parquet_file.iter_batches(batch_size=64)):
            
            # å°†å½“å‰è¿™ä¸€ä¸ªå°æ‰¹æ¬¡è½¬æ¢ä¸º Pandas DataFrame
            df_batch = batch.to_pandas()
            
            for idx, row in df_batch.iterrows():
                try:
                    sample_id = row["id"]
                    
                    # ---------- å›¾ç‰‡ä¿å­˜ ----------
                    # æ³¨æ„ï¼šå¦‚æœæ•°æ®æ ¼å¼æ˜¯ bytesï¼Œç›´æ¥å†™ï¼›å¦‚æœæ˜¯ structï¼Œéœ€è§£æ
                    image_data = row["image"]
                    if isinstance(image_data, dict) and "bytes" in image_data:
                        image_bytes = image_data["bytes"]
                    else:
                        # å…¼å®¹æŸäº›æ ¼å¼ç›´æ¥å°±æ˜¯ bytes çš„æƒ…å†µ
                        image_bytes = image_data
                    
                    image_filename = f"{parquet_name}_{sample_id}.png"
                    image_path = image_output_dir / image_filename
                    
                    # åªæœ‰å½“å›¾ç‰‡ä¸å­˜åœ¨æ—¶æ‰å†™å…¥ï¼ˆå¯é€‰ï¼ŒåŠ å¿«æ–­ç‚¹ç»­ä¼ é€Ÿåº¦ï¼‰
                    # if not image_path.exists(): 
                    with open(image_path, "wb") as f_img:
                        f_img.write(image_bytes)
                    
                    # ---------- å¯¹è¯å¤„ç† ----------
                    messages = []
                    conversations = row["conversations"]
                    
                    for turn in conversations:
                        role = "user" if turn["from"] == "human" else "assistant"
                        text = turn["value"].strip()
                        
                        content = []
                        if role == "user":
                            if text.startswith("<image>"):
                                content.append({"type": "image", "image": str(image_path.resolve())}) # Qwen æ ¼å¼å¾®è°ƒæœ‰æ—¶éœ€è¦æ”¾åœ¨ content é‡Œï¼Œæˆ–è€…å¦‚ä¸‹å¤„ç†
                                # æ³¨æ„ï¼šå¦‚æœæ˜¯ Qwen2-VL åŸç”Ÿæ ¼å¼ï¼Œé€šå¸¸æ˜¯ text é‡Œæ”¾ <image>ï¼Œç„¶å images åˆ—è¡¨æ”¾è·¯å¾„
                                # è¿™é‡Œä¿æŒä½ åŸæœ¬çš„é€»è¾‘ï¼š
                                content.append({"type": "text", "text": "<image>"})
                                rest_text = text.replace("<image>", "").strip()
                                if rest_text:
                                    content.append({"type": "text", "text": rest_text})
                            else:
                                content.append({"type": "text", "text": text})
                        else:
                            content.append({"type": "text", "text": text})
                        
                        messages.append({"role": role, "content": content})
                    
                    # ---------- æ„é€  JSON å®ä¾‹ ----------
                    instance = {
                        "id": f"{parquet_name}_{sample_id}",
                        "images": [str(image_path.resolve())],
                        "messages": messages
                    }
                    
                    # ---------- æµå¼å†™å…¥ JSON ----------
                    if not first_instance:
                        f_json.write(",\n")
                    json.dump(instance, f_json, ensure_ascii=False)
                    first_instance = False
                    
                    global_idx += 1
                    if global_idx % 100 == 0:
                        print(f"  å·²ç´¯è®¡å¤„ç† {global_idx} æ¡æ ·æœ¬...", end="\r")
                
                except Exception as e:
                    print(f"\n[Error] å¤„ç†æ ·æœ¬ {sample_id} å¤±è´¥: {e}")
                    continue

            # --- ä¿®æ”¹ç‚¹ï¼šæ‰‹åŠ¨æ¸…ç†å†…å­˜ ---
            del df_batch
            # æ¯å¤„ç†å®Œå‡ ä¸ª batch å¼ºåˆ¶å›æ”¶ä¸€æ¬¡å†…å­˜
            if batch_idx % 10 == 0:
                gc.collect()

    f_json.write("\n]}\n")

print("\n" + "="*60)
print("âœ… å…¨éƒ¨ parquet æ–‡ä»¶å¤„ç†å®Œæˆ")
print(f"æ€»æ ·æœ¬æ•°: {global_idx}")
print(f"JSON è¾“å‡ºæ–‡ä»¶: {output_json_path}")
print("="*60)

# =========================
# Qwen-VL-7B æ ¼å¼è½¬æ¢
# =========================

INPUT_JSON = "/root/autodl-tmp/coda-lm-llava-format/qwen_test.json"
OUTPUT_JSON = "/root/autodl-tmp/coda-lm-llava-format/qwen_vl_7b_test.json"


def extract_text_from_content(content_list):
    texts = []
    for c in content_list:
        if c.get("type") == "text":
            t = c.get("text", "").strip()
            if t and t != "<image>":
                texts.append(t)
    return "\n".join(texts)


def convert_to_qwen2p5_vl(input_path, output_path):
    with open(input_path, "r", encoding="utf-8") as f:
        raw = json.load(f)

    assert "instances" in raw

    out = []

    for inst in raw["instances"]:
        inst_id = inst["id"]
        image_path = inst["images"][0]

        conversations = []
        first_human = True

        for msg in inst["messages"]:
            role = msg["role"]
            text = extract_text_from_content(msg["content"])
            if not text:
                continue

            if role == "user":
                if first_human:
                    text = "<img>\n" + text
                    first_human = False
                conversations.append({
                    "from": "human",
                    "value": text
                })
            else:
                conversations.append({
                    "from": "assistant",
                    "value": text
                })

        if len(conversations) < 2:
            continue

        out.append({
            "id": inst_id,
            "image": image_path,
            "conversations": conversations
        })

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(out, f, ensure_ascii=False, indent=2)

    print(f"âœ… è½¬æ¢å®Œæˆï¼š{len(out)} æ¡")
    print(f"ğŸ“¤ è¾“å‡ºæ–‡ä»¶ï¼š{output_path}")


if __name__ == "__main__":
    convert_to_qwen2p5_vl(INPUT_JSON, OUTPUT_JSON)
