import json
import random
import time
from openai import OpenAI

# =========================
# 1. åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆSiliconFlow Â· OpenAI Compatibleï¼‰
# =========================
API_KEY = "sk-hyayuucpskezqfipnurdcyonpamhobpgclicouclmbujjgab"
client = OpenAI(
    api_key=API_KEY,
    base_url="https://api.siliconflow.cn/v1",
    timeout=60.0
)

# =========================
# 2. æŒ‡ä»¤æ¨¡æ¿æ± 
# =========================
INSTRUCTION_TEMPLATES = [
    "å½“å‰åœºæ™¯ä¸­æ˜¯å¦å­˜åœ¨æ½œåœ¨é©¾é©¶é£é™©ï¼Ÿè¯·æŒ‡å‡ºå¹¶è§£é‡ŠåŸå› ã€‚",
    "åœ¨è¯¥åœºæ™¯ä¸‹ï¼Œè‡ªè½¦æ˜¯å¦éœ€è¦å‡é€Ÿã€åˆ¶åŠ¨æˆ–å˜é“ï¼Ÿè¯·ç»™å‡ºå†³ç­–ä¾æ®ã€‚",
    "è¯·æŒ‡å‡ºå½“å‰åœºæ™¯ä¸­æœ€å…³é”®çš„ä¸€ä¸ªäº¤é€šå‚ä¸è€…ï¼Œå¹¶è¯´æ˜å…¶ä½ç½®ä¸å½±å“ã€‚",
    "å¦‚æœå‰æ–¹è½¦è¾†çªç„¶ç´§æ€¥åˆ¹è½¦ï¼Œè‡ªè½¦åº”é‡‡å–ä»€ä¹ˆåº”æ€¥ç­–ç•¥ï¼Ÿ",
    "æ ¹æ®å½“å‰é“è·¯ç»“æ„å’Œè½¦è¾†åˆ†å¸ƒï¼Œè‡ªè½¦æœ€å®‰å…¨çš„è¡Œé©¶ç­–ç•¥æ˜¯ä»€ä¹ˆï¼Ÿ",
    "å½“å‰åœºæ™¯ä¸­æ˜¯å¦å­˜åœ¨å¯èƒ½å½±å“é€šè¡Œæ•ˆç‡çš„å› ç´ ï¼Ÿè¯·åˆ†æã€‚",
    "æ˜¯å¦å­˜åœ¨éœ€è¦æå‰é¢„åˆ¤çš„äº¤é€šè¡Œä¸ºï¼Ÿè¯·è¯´æ˜ç†ç”±ã€‚"
]

# =========================
# 3. æ•™å¸ˆæ¨¡å‹ System Prompt
# =========================
TEACHER_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€åä¸“ä¸šçš„è‡ªåŠ¨é©¾é©¶å†³ç­–ä¸é£é™©åˆ†æä¸“å®¶ã€‚
è¯·ä¸¥æ ¼åŸºäºç»™å®šçš„äº¤é€šåœºæ™¯æ–‡å­—æè¿°å›ç­”é—®é¢˜ã€‚
çº¦æŸï¼š
1. åªèƒ½åŸºäºæè¿°ä¸­æ˜ç¡®æåˆ°çš„äº¤é€šè¦ç´ è¿›è¡Œåˆ†æã€‚
2. ä¸å¾—å¼•å…¥æè¿°ä¸­æœªå‡ºç°çš„è½¦è¾†ã€è¡Œäººæˆ–ä¿¡å·è®¾æ–½ã€‚
3. æ‰€æœ‰å†³ç­–å¿…é¡»æœ‰æ˜ç¡®ç†ç”±ï¼Œä¸”é€»è¾‘æ¸…æ™°ã€‚
4. è¯­è¨€ä¸“ä¸šã€å®¢è§‚ã€ç®€æ´ï¼Œé¿å…æ³›æ³›è€Œè°ˆã€‚
"""

# =========================
# 4. æ•™å¸ˆæ¨¡å‹ç”Ÿæˆç­”æ¡ˆ - æ‰¹é‡ç‰ˆæœ¬ (æŒ‰åœºæ™¯æ‰¹é‡)
# =========================
def get_teacher_response_batch(scene_description, question_list):
    """
    ä¸€æ¬¡æ€§ä¸ºä¸€ä¸ªåœºæ™¯çš„å¤šä¸ªé—®é¢˜ç”Ÿæˆç­”æ¡ˆ
    :param scene_description: åœºæ™¯æè¿°
    :param question_list: é—®é¢˜åˆ—è¡¨ï¼Œå¦‚ [q1, q2, q3]
    :return: ç­”æ¡ˆåˆ—è¡¨ï¼Œä¸é—®é¢˜é¡ºåºå¯¹åº”ï¼Œå¦‚ [ans1, ans2, ans3]
    """
    try:
        print(f"    ğŸ¤– æ­£åœ¨æ‰¹é‡ç”Ÿæˆ {len(question_list)} ä¸ªé—®é¢˜çš„åˆ†æ...")
        start_time = time.time()
        
        responses = []
        for q in question_list:
            user_question = f"åŸºäºä¸Šè¿°äº¤é€šåœºæ™¯ï¼Œ{q}"
            response = client.chat.completions.create(
                model="Qwen/Qwen3-8B",
                messages=[
                    {"role": "system", "content": TEACHER_SYSTEM_PROMPT},
                    {
                        "role": "user",
                        "content": (
                            f"äº¤é€šåœºæ™¯æè¿°å¦‚ä¸‹ï¼š\n"
                            f"{scene_description}\n\n"
                            f"é—®é¢˜ï¼š{user_question}"
                        )
                    }
                ],
                temperature=0.5,
                max_tokens=300,
                timeout=30.0
            )
            answer = response.choices[0].message.content.strip()
            responses.append(answer)
        
        elapsed_time = time.time() - start_time
        avg_time_per_question = elapsed_time / len(question_list)
        print(f"    âœ… æ‰¹é‡ç”ŸæˆæˆåŠŸ (å…±è€—æ—¶{elapsed_time:.1f}ç§’ï¼Œ å¹³å‡æ¯ä¸ªé—®é¢˜{avg_time_per_question:.1f}ç§’)")
        for i, ans in enumerate(responses):
            preview = ans[:50] + "..." if len(ans) > 50 else ans
            print(f"      é—®é¢˜{i+1}æ‘˜è¦: {preview}")
        return responses
        
    except Exception as e:
        print(f"    âŒ æ‰¹é‡è°ƒç”¨å¤±è´¥: {e}")
        return [None] * len(question_list)

# =========================
# 5. æ•°æ®å¢å¼ºä¸»æµç¨‹ï¼ˆå·²é›†æˆæ‰¹é‡å¤„ç†ï¼‰
# =========================
def process_and_augment_data(
    input_json_path,
    output_json_path,
    num_questions_per_image=2
):
    print("ğŸ“‚ æ­£åœ¨è¯»å–åŸå§‹æ•°æ®æ–‡ä»¶...")
    with open(input_json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    total_instances = len(data["instances"])
    print(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆï¼Œå…±å‘ç° {total_instances} ä¸ªäº¤é€šåœºæ™¯å®ä¾‹")
    print("="*60)
    
    processed_count = 0
    enhanced_qa_pairs = 0
    total_start_time = time.time()
    
    for idx, item in enumerate(data["instances"]):
        processed_count += 1
        messages = item["messages"]
        
        original_description = None
        for msg in messages:
            if msg["role"] == "assistant":
                original_description = msg["content"][0]["text"]
                break
        
        if not original_description:
            print(f"[{idx+1}/{total_instances}] âš ï¸  è·³è¿‡ {item['id']}: æœªæ‰¾åˆ°åœºæ™¯æè¿°")
            continue
        
        available_questions = min(num_questions_per_image, len(INSTRUCTION_TEMPLATES))
        selected_questions = random.sample(INSTRUCTION_TEMPLATES, k=available_questions)
        
        scene_preview = original_description[:80] + "..." if len(original_description) > 80 else original_description
        print(f"[{idx+1}/{total_instances}] ğŸš— å¤„ç† {item['id']}")
        print(f"   æè¿°é¢„è§ˆ: {scene_preview}")
        print(f"   å°†ä¸ºè¯¥åœºæ™¯ç”Ÿæˆ {len(selected_questions)} ä¸ªå¢å¼ºé—®é¢˜")
        
        all_questions_for_this_scene = []
        for q in selected_questions:
            user_question = f"åŸºäºä¸Šè¿°äº¤é€šåœºæ™¯ï¼Œ{q}"
            all_questions_for_this_scene.append(user_question)
        
        answers = get_teacher_response_batch(original_description, selected_questions)
        
        for user_question, answer in zip(all_questions_for_this_scene, answers):
            if answer is None:
                print(f"   âš ï¸  é—®é¢˜ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡: {user_question[:30]}...")
                continue
                
            messages.append({
                "role": "user",
                "content": [{"type": "text", "text": user_question}]
            })
            messages.append({
                "role": "assistant",
                "content": [{"type": "text", "text": answer}]
            })
            enhanced_qa_pairs += 1
        
        print(f"   ğŸ“ æœ¬åœºæ™¯å¤„ç†å®Œæˆï¼ŒæˆåŠŸå¢åŠ  {len([a for a in answers if a is not None])} ä¸ªQAå¯¹")
        time.sleep(0.1)
        print("-"*50)
    
    total_elapsed_time = time.time() - total_start_time
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜å¢å¼ºåçš„æ•°æ®åˆ° {output_json_path}...")
    with open(output_json_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print("="*60)
    print(f"ğŸ‰ æ•°æ®å¢å¼ºå®Œæˆï¼")
    print(f"   â€¢ æ€»è€—æ—¶: {total_elapsed_time / 3600:.2f} å°æ—¶")
    print(f"   â€¢ å…±å¤„ç†åœºæ™¯: {processed_count}/{total_instances}")
    print(f"   â€¢ æ–°å¢QAå¯¹è¯å¯¹: {enhanced_qa_pairs}")
    print(f"   â€¢ å¹³å‡æ¯ä¸ªåœºæ™¯è€—æ—¶: {total_elapsed_time / processed_count if processed_count else 0:.2f} ç§’")
    print(f"   â€¢ è¾“å‡ºæ–‡ä»¶: {output_json_path}")
    print("="*60)


# =========================
# 6. Qwen-VL-7B æ ¼å¼è½¬æ¢
# =========================
INPUT_JSON = "qwen_finetune.json"
OUTPUT_JSON = "qwen_vl_7b.json"


def extract_text_from_content(content_list):
    texts = []
    for c in content_list:
        if c.get("type") == "text":
            texts.append(c.get("text", "").strip())
    return "\n".join([t for t in texts if t])


def convert_to_qwen_vl7b(input_path, output_path):
    with open(input_path, "r", encoding="utf-8") as f:
        raw_data = json.load(f)

    assert "instances" in raw_data, "âŒ è¾“å…¥ JSON ä¸åŒ…å« instances å­—æ®µ"

    output_data = []

    for inst in raw_data["instances"]:
        inst_id = inst.get("id", "")
        images = inst.get("images", [])
        messages = inst.get("messages", [])

        if not images:
            continue

        image_path = images[0]

        conversations = []
        first_human = True

        for msg in messages:
            role = msg.get("role")
            content = msg.get("content", [])

            text = extract_text_from_content(content)
            if not text:
                continue

            if role == "user":
                if first_human:
                    text = "<img>\n" + text
                    first_human = False

                conversations.append({
                    "from": "human",
                    "value": text
                })

            elif role == "assistant":
                conversations.append({
                    "from": "assistant",
                    "value": text
                })

        if len(conversations) < 2:
            continue

        output_data.append({
            "id": inst_id,
            "image": image_path,
            "conversations": conversations
        })

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print("âœ… è½¬æ¢å®Œæˆ")
    print(f"ğŸ“¥ è¾“å…¥æ–‡ä»¶: {input_path}")
    print(f"ğŸ“¤ è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"ğŸ“Š æ ·æœ¬æ•°é‡: {len(output_data)}")


# =========================
# 7. Main
# =========================
if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹äº¤é€šåœºæ™¯æ•°æ®å¢å¼ºæµç¨‹")
    print(f"ä½¿ç”¨çš„æ•™å¸ˆæ¨¡å‹: Qwen/Qwen3-8B")
    print(f"ä¼˜åŒ–ç­–ç•¥: åœºæ™¯å†…é—®é¢˜æ‰¹é‡å¤„ç† | ç”Ÿæˆé•¿åº¦é™åˆ¶:200 | è°ƒç”¨é—´éš”ç¼©çŸ­:0.5ç§’")
    print(f"æŒ‡ä»¤æ¨¡æ¿æ± : {len(INSTRUCTION_TEMPLATES)} ä¸ªé¢„è®¾é—®é¢˜")
    print("="*60)

    process_and_augment_data(
        input_json_path="qwen_finetune.json",
        output_json_path="qwen_finetune_aug_batch_optimized.json",
        num_questions_per_image=2
    )

    convert_to_qwen_vl7b(
        INPUT_JSON,
        OUTPUT_JSON
    )

