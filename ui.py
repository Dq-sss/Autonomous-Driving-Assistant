import torch
import time
from transformers import AutoModelForImageTextToText, AutoProcessor
from peft import PeftModel
import gradio as gr

# =========================
# 1. æ¨¡å‹åŠ è½½
# =========================
print("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹ï¼Œè¯·ç¨å€™...")

BASE_MODEL_PATH = "/root/autodl-fs/Qwen2.5-VL-7B-Instruct"
LORA_PATH = "output"

print("åŠ è½½åŸºç¡€æ¨¡å‹...")
base_model = AutoModelForImageTextToText.from_pretrained(
    BASE_MODEL_PATH,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True
)

print("åŠ è½½ LoRA...")
model = PeftModel.from_pretrained(base_model, LORA_PATH)
model.eval()

print("åŠ è½½ Processor...")
try:
    processor = AutoProcessor.from_pretrained(LORA_PATH, trust_remote_code=True)
except:
    processor = AutoProcessor.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True)

print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

# =========================
# 2. é»˜è®¤ Prompt
# =========================
DEFAULT_PROMPT = (
    "è¿™æ˜¯ä¸€å¼ ä»è‡ªè½¦è§†è§’æ•æ‰çš„äº¤é€šå›¾åƒã€‚é‡ç‚¹å…³æ³¨å½±å“è‡ªè½¦é©¾é©¶è¡Œä¸ºçš„ç‰©ä½“ï¼š"
    "è½¦è¾†ã€è¡Œäººã€è‡ªè¡Œè½¦ã€äº¤é€šæ ‡å¿—ã€ä¿¡å·ç¯ã€äº¤é€šé”¥ã€éšœç¢ç‰©ã€‚"
    "è¯·æè¿°å®ƒä»¬çš„ä½ç½®ã€çŠ¶æ€åŠå¯¹é©¾é©¶çš„å½±å“ã€‚"
)

# =========================
# 3. æ¨ç†å‡½æ•°
# =========================
def generate_response(image, text):
    if image is None:
        return "è¯·ä¸Šä¼ å›¾ç‰‡"
    if not text:
        return "è¯·è¾“å…¥æç¤ºè¯"

    messages = [{
        "role": "user",
        "content": [
            {"type": "image", "image": image},
            {"type": "text", "text": text}
        ]
    }]

    prompt = processor.apply_chat_template(
        messages, tokenize=False, add_generation_prompt=True
    )

    inputs = processor(
        text=[prompt],
        images=[image],
        return_tensors="pt",
        padding=True
    ).to(model.device)

    start = time.time()
    with torch.no_grad():
        output_ids = model.generate(
            **inputs,
            max_new_tokens=512,
            do_sample=False
        )

    output_ids = output_ids[:, inputs.input_ids.shape[1]:]
    result = processor.batch_decode(
        output_ids,
        skip_special_tokens=True
    )[0]

    return result + f"\n\nâ± æ¨ç†è€—æ—¶ {time.time() - start:.2f}s"

# =========================
# 4. Gradio é€»è¾‘
# =========================
def chat(image, text, history):
    history = history or []
    history.append([text, generate_response(image, text)])
    return history, ""

def clear():
    return None, DEFAULT_PROMPT, []

# =========================
# 5. Gradio UI
# =========================
with gr.Blocks(title="Qwen2.5-VL Traffic Assistant") as demo:
    gr.Markdown("# ğŸš— Qwen2.5-VL äº¤é€šåœºæ™¯ç†è§£")

    with gr.Row():
        image = gr.Image(type="pil", label="è¾“å…¥å›¾åƒ", height=400)
        chatbot = gr.Chatbot(height=400)

    text = gr.Textbox(
        lines=5,
        value=DEFAULT_PROMPT,
        label="æç¤ºè¯"
    )

    with gr.Row():
        submit = gr.Button("åˆ†æ")
        clear_btn = gr.Button("æ¸…ç©º")

    submit.click(chat, [image, text, chatbot], [chatbot, text])
    clear_btn.click(clear, [], [image, text, chatbot])

# =========================
# 6. å¯åŠ¨ï¼ˆå…³é”®ä¿®æ”¹åœ¨è¿™é‡Œï¼‰
# =========================
if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=6006,
        share=False,
        show_api=False,   # ğŸ”¥ å…³é”®ï¼šå…³é—­ API schema
        inbrowser=False
    )
